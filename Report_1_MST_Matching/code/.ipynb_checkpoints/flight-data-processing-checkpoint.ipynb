{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e55b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbb37a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1043105</td>\n",
       "      <td>1393007</td>\n",
       "      <td>120.0</td>\n",
       "      <td>536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1106606</td>\n",
       "      <td>1393007</td>\n",
       "      <td>88.0</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1062702</td>\n",
       "      <td>1129202</td>\n",
       "      <td>117.0</td>\n",
       "      <td>516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1129806</td>\n",
       "      <td>1477104</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1110902</td>\n",
       "      <td>1129202</td>\n",
       "      <td>36.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FL_DATE  ORIGIN_AIRPORT_SEQ_ID  DEST_AIRPORT_SEQ_ID  \\\n",
       "0  8/1/2022 12:00:00 AM                1043105              1393007   \n",
       "1  8/1/2022 12:00:00 AM                1106606              1393007   \n",
       "2  8/1/2022 12:00:00 AM                1062702              1129202   \n",
       "3  8/1/2022 12:00:00 AM                1129806              1477104   \n",
       "4  8/1/2022 12:00:00 AM                1110902              1129202   \n",
       "\n",
       "   ACTUAL_ELAPSED_TIME  DISTANCE  \n",
       "0                120.0     536.0  \n",
       "1                 88.0     296.0  \n",
       "2                117.0     516.0  \n",
       "3                232.0    1464.0  \n",
       "4                 36.0      73.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_data = pd.read_csv('..\\data\\T_ONTIME_REPORTING.csv', index_col=None, header=0)\n",
    "flight_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a035f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRPORT_SEQ_ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000101</td>\n",
       "      <td>58.109444</td>\n",
       "      <td>-152.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000301</td>\n",
       "      <td>65.548056</td>\n",
       "      <td>-161.071667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000401</td>\n",
       "      <td>68.083333</td>\n",
       "      <td>-163.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000501</td>\n",
       "      <td>67.570000</td>\n",
       "      <td>-148.183889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000601</td>\n",
       "      <td>57.745278</td>\n",
       "      <td>-152.882778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIRPORT_SEQ_ID   LATITUDE   LONGITUDE\n",
       "0         1000101  58.109444 -152.906667\n",
       "1         1000301  65.548056 -161.071667\n",
       "2         1000401  68.083333 -163.166667\n",
       "3         1000501  67.570000 -148.183889\n",
       "4         1000601  57.745278 -152.882778"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_coordinates = pd.read_csv('..\\data\\L_AIRPORT_COORDINATES.csv', index_col=None, header=0)\n",
    "airport_coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52987115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000101</td>\n",
       "      <td>Afognak Lake, AK: Afognak Lake Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000301</td>\n",
       "      <td>Granite Mountain, AK: Bear Creek Mining Strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000401</td>\n",
       "      <td>Lik, AK: Lik Mining Camp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000501</td>\n",
       "      <td>Little Squaw, AK: Little Squaw Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000601</td>\n",
       "      <td>Kizhuyak, AK: Kizhuyak Bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                    Description\n",
       "0  1000101         Afognak Lake, AK: Afognak Lake Airport\n",
       "1  1000301  Granite Mountain, AK: Bear Creek Mining Strip\n",
       "2  1000401                       Lik, AK: Lik Mining Camp\n",
       "3  1000501         Little Squaw, AK: Little Squaw Airport\n",
       "4  1000601                     Kizhuyak, AK: Kizhuyak Bay"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_id = pd.read_csv('..\\data\\L_AIRPORT_SEQ_ID.csv', index_col=None, header=0)\n",
    "airports_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588af1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>DEST_AIRPORT_SEQ_ID</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1043105</td>\n",
       "      <td>1393007</td>\n",
       "      <td>120.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>35.434444</td>\n",
       "      <td>-82.542778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1043105</td>\n",
       "      <td>1105703</td>\n",
       "      <td>64.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>35.434444</td>\n",
       "      <td>-82.542778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1043105</td>\n",
       "      <td>1295304</td>\n",
       "      <td>108.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>35.434444</td>\n",
       "      <td>-82.542778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1043105</td>\n",
       "      <td>1295304</td>\n",
       "      <td>108.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>35.434444</td>\n",
       "      <td>-82.542778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/1/2022 12:00:00 AM</td>\n",
       "      <td>1043105</td>\n",
       "      <td>1105703</td>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>35.434444</td>\n",
       "      <td>-82.542778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589805</th>\n",
       "      <td>8/14/2022 12:00:00 AM</td>\n",
       "      <td>1490505</td>\n",
       "      <td>1288903</td>\n",
       "      <td>97.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>-120.458056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589806</th>\n",
       "      <td>8/19/2022 12:00:00 AM</td>\n",
       "      <td>1490505</td>\n",
       "      <td>1288903</td>\n",
       "      <td>74.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>-120.458056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589807</th>\n",
       "      <td>8/21/2022 12:00:00 AM</td>\n",
       "      <td>1490505</td>\n",
       "      <td>1288903</td>\n",
       "      <td>93.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>-120.458056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589808</th>\n",
       "      <td>8/26/2022 12:00:00 AM</td>\n",
       "      <td>1490505</td>\n",
       "      <td>1288903</td>\n",
       "      <td>88.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>-120.458056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589809</th>\n",
       "      <td>8/28/2022 12:00:00 AM</td>\n",
       "      <td>1490505</td>\n",
       "      <td>1288903</td>\n",
       "      <td>89.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>-120.458056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589810 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FL_DATE  ORIGIN_AIRPORT_SEQ_ID  DEST_AIRPORT_SEQ_ID  \\\n",
       "0        8/1/2022 12:00:00 AM                1043105              1393007   \n",
       "1        8/1/2022 12:00:00 AM                1043105              1105703   \n",
       "2        8/1/2022 12:00:00 AM                1043105              1295304   \n",
       "3        8/1/2022 12:00:00 AM                1043105              1295304   \n",
       "4        8/1/2022 12:00:00 AM                1043105              1105703   \n",
       "...                       ...                    ...                  ...   \n",
       "589805  8/14/2022 12:00:00 AM                1490505              1288903   \n",
       "589806  8/19/2022 12:00:00 AM                1490505              1288903   \n",
       "589807  8/21/2022 12:00:00 AM                1490505              1288903   \n",
       "589808  8/26/2022 12:00:00 AM                1490505              1288903   \n",
       "589809  8/28/2022 12:00:00 AM                1490505              1288903   \n",
       "\n",
       "        ACTUAL_ELAPSED_TIME  DISTANCE   LATITUDE   LONGITUDE  \n",
       "0                     120.0     536.0  35.434444  -82.542778  \n",
       "1                      64.0      91.0  35.434444  -82.542778  \n",
       "2                     108.0     599.0  35.434444  -82.542778  \n",
       "3                     108.0     599.0  35.434444  -82.542778  \n",
       "4                      66.0      91.0  35.434444  -82.542778  \n",
       "...                     ...       ...        ...         ...  \n",
       "589805                 97.0     310.0  34.900000 -120.458056  \n",
       "589806                 74.0     310.0  34.900000 -120.458056  \n",
       "589807                 93.0     310.0  34.900000 -120.458056  \n",
       "589808                 88.0     310.0  34.900000 -120.458056  \n",
       "589809                 89.0     310.0  34.900000 -120.458056  \n",
       "\n",
       "[589810 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_coordinates = airport_coordinates.rename(columns={\"AIRPORT_SEQ_ID\": \"ORIGIN_AIRPORT_SEQ_ID\"})\n",
    "pd.merge(flight_data, airport_coordinates, on='ORIGIN_AIRPORT_SEQ_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9ecf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyspark\n",
    "except:\n",
    "    !pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff58ee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--test] [--epsilon EPSILON] [--machines MACHINES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\20191929\\AppData\\Roaming\\jupyter\\runtime\\kernel-62e08af4-baa9-49b7-b1be-c21fceff6890.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import csv\n",
    "import random\n",
    "import scipy.spatial\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import make_circles, make_moons, make_blobs, make_swiss_roll, make_s_curve\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from Plotter import *\n",
    "from DataReader import *\n",
    "\n",
    "\n",
    "def get_clustering_data():\n",
    "    \"\"\"\n",
    "    Retrieves all toy datasets from sklearn\n",
    "    :return: circles, moons, blobs datasets.\n",
    "    \"\"\"\n",
    "    n_samples = 1500\n",
    "    noisy_circles = make_circles(n_samples=n_samples, factor=.5,\n",
    "                                 noise=0.05)\n",
    "    noisy_moons = make_moons(n_samples=n_samples, noise=0.05)\n",
    "    blobs = make_blobs(n_samples=n_samples, random_state=8)\n",
    "    no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "    # Anisotropicly distributed data\n",
    "    random_state = 170\n",
    "    X, y = make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "    X_aniso = np.dot(X, transformation)\n",
    "    aniso = (X_aniso, y)\n",
    "\n",
    "    # blobs with varied variances\n",
    "    varied = make_blobs(n_samples=n_samples,\n",
    "                        cluster_std=[1.0, 2.5, 0.5],\n",
    "                        random_state=random_state)\n",
    "\n",
    "    plt.figure(figsize=(9 * 2 + 3, 13))\n",
    "    plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.95, wspace=.05,\n",
    "                        hspace=.01)\n",
    "\n",
    "    swiss_roll = make_swiss_roll(n_samples, noise=0.05)\n",
    "\n",
    "    s_shape = make_s_curve(n_samples, noise=0.05)\n",
    "\n",
    "    datasets = [\n",
    "        (noisy_circles, {'damping': .77, 'preference': -240,\n",
    "                         'quantile': .2, 'n_clusters': 2,\n",
    "                         'min_samples': 20, 'xi': 0.25}),\n",
    "        (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
    "        (varied, {'eps': .18, 'n_neighbors': 2,\n",
    "                  'min_samples': 5, 'xi': 0.035, 'min_cluster_size': .2}),\n",
    "        (aniso, {'eps': .15, 'n_neighbors': 2,\n",
    "                 'min_samples': 20, 'xi': 0.1, 'min_cluster_size': .2}),\n",
    "        (blobs, {}),\n",
    "        (no_structure, {}),\n",
    "        (swiss_roll, {}),\n",
    "        (s_shape, {})]\n",
    "\n",
    "    return datasets\n",
    "\n",
    "def create_distance_matrix(dataset):\n",
    "    \"\"\"\n",
    "    Creates the distance matrix for a dataset with only vertices. Also adds the edges to a dict.\n",
    "    :param dataset: dataset without edges\n",
    "    :return: distance matrix, a dict of all edges and the total number of edges\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    size = 0\n",
    "    three_d = False\n",
    "    for line in dataset:\n",
    "        if len(line) == 2:\n",
    "            vertices.append([line[0], line[1]])\n",
    "        elif len(line) == 3:\n",
    "            vertices.append([line[0], line[1], line[2]])\n",
    "            three_d = True\n",
    "    if three_d:\n",
    "        dict = {}\n",
    "        for i in range(len(dataset)):\n",
    "            dict2 = {}\n",
    "            for j in range(i + 1, len(dataset)):\n",
    "                dict2[j] = np.sqrt(np.sum(np.square(dataset[i] - dataset[j])))\n",
    "                size += 1\n",
    "            dict[i] = dict2\n",
    "\n",
    "    else:\n",
    "        d_matrix = scipy.spatial.distance_matrix(vertices, vertices, threshold=1000000)\n",
    "        dict = {}\n",
    "        # Run with less edges\n",
    "        for i in range(len(d_matrix)):\n",
    "            dict2 = {}\n",
    "            for j in range(i, len(d_matrix)):\n",
    "                if i != j:\n",
    "                    size += 1\n",
    "                    dict2[j] = d_matrix[i][j]\n",
    "            dict[i] = dict2\n",
    "    return dict, size, vertices\n",
    "\n",
    "\n",
    "\n",
    "def partion_vertices(vertices, k):\n",
    "    \"\"\"\n",
    "    Partitioning of the vertices in k smaller subsets (creates a partitioning twice\n",
    "    :param vertices: all vertices\n",
    "    :param k: number of subsets that need to be created\n",
    "    :return: the partitioning in list format\n",
    "    \"\"\"\n",
    "    U = []\n",
    "    V = []\n",
    "    random.shuffle(vertices)\n",
    "    verticesU = vertices.copy()\n",
    "    random.shuffle(vertices)\n",
    "    verticesV = vertices.copy()\n",
    "    for i in range(len(vertices)):\n",
    "        if i < k:\n",
    "            U.append({verticesU[i]})\n",
    "            V.append({verticesV[i]})\n",
    "        else:\n",
    "            U[i % k].add(verticesU[i])\n",
    "            V[i % k].add(verticesV[i])\n",
    "    return U, V\n",
    "\n",
    "\n",
    "def get_key(item):\n",
    "    \"\"\"\n",
    "    returns the sorting criteria for the edges. All edges are sorted from small to large values\n",
    "    :param item: one item\n",
    "    :return: returns the weight of the edge\n",
    "    \"\"\"\n",
    "    return item[2]\n",
    "\n",
    "\n",
    "def find_mst(U, V, E):\n",
    "    \"\"\"\n",
    "    finds the mst of graph G = (U union V, E)\n",
    "    :param U: vertices U\n",
    "    :param V: vertices V\n",
    "    :param E: edges of the graph\n",
    "    :return: the mst and edges not in the mst of the graph\n",
    "     \"\"\"\n",
    "    vertices = set()\n",
    "    for v in V:\n",
    "        vertices.add(v)\n",
    "    for u in U:\n",
    "        vertices.add(u)\n",
    "    E = sorted(E, key=get_key)\n",
    "    connected_component = set()\n",
    "    mst = []\n",
    "    remove_edges = set()\n",
    "    while len(mst) < len(vertices) - 1 and len(connected_component) < len(vertices):\n",
    "        if len(E) == 0:\n",
    "            break\n",
    "        change = False\n",
    "        i = 0\n",
    "        while i < len(E):\n",
    "            if len(connected_component) == 0:\n",
    "                connected_component.add(E[i][0])\n",
    "                connected_component.add(E[i][1])\n",
    "                mst.append(E[i])\n",
    "                change = True\n",
    "                E.remove(E[i])\n",
    "                break\n",
    "            else:\n",
    "                if E[i][0] in connected_component:\n",
    "                    if E[i][1] in connected_component:\n",
    "                        remove_edges.add(E[i])\n",
    "                        E.remove(E[i])\n",
    "                    else:\n",
    "                        connected_component.add(E[i][1])\n",
    "                        mst.append(E[i])\n",
    "                        E.remove(E[i])\n",
    "                        change = True\n",
    "                        break\n",
    "                elif E[i][1] in connected_component:\n",
    "                    if E[i][0] in connected_component:\n",
    "                        remove_edges.add(E[i])\n",
    "                        E.remove(E[i])\n",
    "                    else:\n",
    "                        connected_component.add(E[i][0])\n",
    "                        mst.append(E[i])\n",
    "                        E.remove(E[i])\n",
    "                        change = True\n",
    "                        break\n",
    "                else:\n",
    "                    i += 1\n",
    "        if not change:\n",
    "            if len(E) != 0:\n",
    "                connected_component.add(E[0][0])\n",
    "                connected_component.add(E[0][1])\n",
    "                mst.append(E[0])\n",
    "                E.remove(E[0])\n",
    "    for edge in E:\n",
    "        remove_edges.add(edge)\n",
    "    if len(mst) != len(vertices) - 1 or len(connected_component) != len(vertices):\n",
    "        print('Warning: parition cannot have a full MST! Missing edges to create full MST.')\n",
    "        # print('Error: MST found cannot be correct \\n Length mst: ', len(mst), '\\n Total connected vertices: ',\n",
    "        #       len(connected_component), '\\n Number of vertices: ', len(vertices))\n",
    "    return mst, remove_edges\n",
    "\n",
    "\n",
    "def get_edges(U, V, E):\n",
    "    \"\"\"\n",
    "    :param U: subset of vertices (u_j)\n",
    "    :param V: subset of vertices (v_i)\n",
    "    :param E: all edges of the whole graph\n",
    "    :return: all edges that are part of the graph u_j U v_j\n",
    "    \"\"\"\n",
    "    edges = set()\n",
    "    for node1 in U:\n",
    "        for node2 in V:\n",
    "            if node1 in E:\n",
    "                if node2 in E[node1]:\n",
    "                    edges.add((node1, node2, E[node1][node2]))\n",
    "                elif node2 in E:\n",
    "                    if node1 in E[node2]:\n",
    "                        edges.add((node2, node1, E[node2][node1]))\n",
    "            elif node2 in E:\n",
    "                if node1 in E[node2]:\n",
    "                    edges.add((node2, node1, E[node2][node1]))\n",
    "    edge_list = []\n",
    "    for edge in edges:\n",
    "        edge_list.append(edge)\n",
    "    return U, V, edge_list\n",
    "\n",
    "\n",
    "def reduce_edges(vertices, E, c, epsilon):\n",
    "    \"\"\"\n",
    "    Uses PySpark to distribute the computation of the MSTs,\n",
    "    Randomly partition the vertices twice in k subsets (U = {u_1, u_2, .., u_k}, V = {v_1, v_2, .., v_k})\n",
    "    For every intersection between U_i and V_j, create the subgraph and find the MST in this graph\n",
    "    Remove all edges from E that are not part of the MST in the subgraph\n",
    "    :param vertices: vertices in the graph\n",
    "    :param E: edges of the graph\n",
    "    :param c: constant\n",
    "    :param epsilon:\n",
    "    :return:The reduced number of edges\n",
    "    \"\"\"\n",
    "    conf = SparkConf().setAppName('MST_Algorithm')\n",
    "    sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "    n = len(vertices)\n",
    "    k = math.ceil(n ** ((c - epsilon) / 2))\n",
    "    print(\"k: \", k)\n",
    "    U, V = partion_vertices(vertices, k)\n",
    "\n",
    "    rddUV = sc.parallelize(U).cartesian(sc.parallelize(V)).map(lambda x: get_edges(x[0], x[1], E)).map(\n",
    "        lambda x: (find_mst(x[0], x[1], x[2])))\n",
    "    both = rddUV.collect()\n",
    "\n",
    "    mst = []\n",
    "    removed_edges = set()\n",
    "    for i in range(len(both)):\n",
    "        mst.append(both[i][0])\n",
    "        for edge in both[i][1]:\n",
    "            removed_edges.add(edge)\n",
    "\n",
    "    sc.stop()\n",
    "    return mst, removed_edges\n",
    "\n",
    "\n",
    "def remove_edges(E, removed_edges):\n",
    "    \"\"\"\n",
    "    Removes the edges, which are removed when generating msts\n",
    "    :param E: current edges\n",
    "    :param removed_edges: edges to be removed\n",
    "    :return: return the updated edge dict\n",
    "    \"\"\"\n",
    "    for edge in removed_edges:\n",
    "        if edge[1] in E[edge[0]]:\n",
    "            del E[edge[0]][edge[1]]\n",
    "    return E\n",
    "\n",
    "\n",
    "def create_mst(V, E, epsilon, size, vertex_coordinates, plot_intermediate=False, plotter=None):\n",
    "    \"\"\"\n",
    "    Creates the mst of the graph G = (V, E).\n",
    "    As long as the number of edges is greater than n ^(1 + epsilon), the number of edges is reduced\n",
    "    Then the edges that needs to be removed are removed from E and the size is updated.\n",
    "    :param plotter: class to plot graphs\n",
    "    :param V: Vertices\n",
    "    :param E: edges\n",
    "    :param epsilon:\n",
    "    :param size: number of edges\n",
    "    :param plot_intermediate: boolean to indicate if intermediate steps should be plotted\n",
    "    :param vertex_coordinates: coordinates of vertices\n",
    "    :return: returns the reduced graph with at most np.power(n, 1 + epsilon) edges\n",
    "    \"\"\"\n",
    "    n = len(V)\n",
    "    c = math.log(size / n, n)\n",
    "    print(\"C\", c)\n",
    "    total_runs = 0\n",
    "    while size > np.power(n, 1 + epsilon):\n",
    "        total_runs += 1\n",
    "        if plotter is not None:\n",
    "            plotter.next_round()\n",
    "        mst, removed_edges = reduce_edges(V, E, c, epsilon)\n",
    "        if plot_intermediate and plotter is not None:\n",
    "            if len(vertex_coordinates[0]) > 2:\n",
    "                plotter.plot_mst_3d(mst, intermediate=True, plot_cluster=False, plot_num_machines=1)\n",
    "            else:\n",
    "                plotter.plot_mst_2d(mst, intermediate=True, plot_cluster=False, plot_num_machines=1)\n",
    "        E = remove_edges(E, removed_edges)\n",
    "        print('Total edges removed in this iteration', len(removed_edges))\n",
    "        size = size - len(removed_edges)\n",
    "        print('New total of edges: ', size)\n",
    "        c = (c - epsilon) / 2\n",
    "    # Now the number of edges is reduced and can be moved to a single machine\n",
    "    V = set(range(n))\n",
    "    items = E.items()  # returns [(x, {y : 1})]\n",
    "    edges = []\n",
    "    for item in items:\n",
    "        items2 = item[1].items()\n",
    "        for item2 in items2:\n",
    "            edges.append((item[0], item2[0], item2[1]))\n",
    "    mst, removed_edges = find_mst(V, V, edges)\n",
    "    print(\"#####\\n\\nTotal runs: \", total_runs, \"\\n\\n#####\")\n",
    "    return mst\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    For every dataset, it creates the mst and plots the clustering\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--test', help='Used for smaller dataset and testing', action='store_true')\n",
    "    parser.add_argument('--epsilon', help='epsilon [default=1/8]', type=float, default=1 / 8)\n",
    "    parser.add_argument('--machines', help='Number of machines [default=1]', type=int, default=1)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print('Start generating MST')\n",
    "    if args.test:\n",
    "        print('Test argument given')\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print('Starting time:', start_time)\n",
    "\n",
    "    datasets = get_clustering_data()\n",
    "    names_datasets = ['TwoCircles', 'TwoMoons', 'Varied', 'Aniso', 'Blobs', 'Random', 'swissroll', 'sshape']\n",
    "    # datasets = []\n",
    "\n",
    "    num_clusters = [2, 2, 3, 3, 3, 2, 2, 2]\n",
    "    cnt = 0\n",
    "    time = []\n",
    "    file_location = 'Results/test/'\n",
    "    plotter = Plotter(None, None, file_location)\n",
    "    data_reader = DataReader()\n",
    "    for dataset in datasets:\n",
    "        if cnt < 0:\n",
    "            cnt += 1\n",
    "            continue\n",
    "        timestamp = datetime.now()\n",
    "        print('Start creating Distance Matrix...')\n",
    "        E, size, vertex_coordinates = create_distance_matrix(dataset[0][0])\n",
    "        plotter.set_vertex_coordinates(vertex_coordinates)\n",
    "        plotter.set_dataset(names_datasets[cnt])\n",
    "        plotter.update_string()\n",
    "        plotter.reset_round()\n",
    "        V = list(range(len(vertex_coordinates)))\n",
    "        print('Size dataset: ', len(vertex_coordinates))\n",
    "        print('Created distance matrix in: ', datetime.now() - timestamp)\n",
    "        print('Start creating MST...')\n",
    "        timestamp = datetime.now()\n",
    "        mst = create_mst(V, E, epsilon=args.epsilon, size=size, vertex_coordinates=vertex_coordinates,\n",
    "                         plot_intermediate=True, plotter=plotter)\n",
    "        print('Found MST in: ', datetime.now() - timestamp)\n",
    "        time.append(datetime.now() - timestamp)\n",
    "        print('Start creating plot of MST...')\n",
    "        timestamp = datetime.now()\n",
    "        if len(vertex_coordinates[0]) > 2:\n",
    "            plotter.plot_mst_3d(mst, intermediate=False, plot_cluster=False, num_clusters=num_clusters[cnt])\n",
    "        else:\n",
    "            plotter.plot_mst_2d(mst, intermediate=False, plot_cluster=False, num_clusters=num_clusters[cnt])\n",
    "        print('Created plot of MST in: ', datetime.now() - timestamp)\n",
    "        cnt += 1\n",
    "\n",
    "    # Read form file location\n",
    "    # loc_array = ['datasets/Brightkite_edges.txt', 'datasets/CA-AstroPh.txt', 'datasets/com-amazon.ungraph.txt',\n",
    "    # 'datasets/facebook_combined.txt'\n",
    "    # ]\n",
    "    # loc = 'datasets/Brightkite_edges.txt'\n",
    "    loc = 'datasets/CA-AstroPh.txt'\n",
    "    # loc = 'datasets/facebook_combined.txt'\n",
    "    # loc = 'datasets/polygons/rvisp24116.instance.json'\n",
    "    print('Read dataset: ', loc)\n",
    "    timestamp = datetime.now()\n",
    "    # V, size, E, vertex_coordinates = data_reader.read_json(loc)\n",
    "    V, size, E = data_reader.read_data_set_from_txtfile(loc)\n",
    "    print('Time to read dataset: ', datetime.now() - timestamp)\n",
    "    print('Size dataset: ', size)\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    mst = create_mst(V, E, epsilon=args.epsilon, size=size, vertex_coordinates=None, plot_intermediate=False)\n",
    "    c = [[121399]]\n",
    "\n",
    "    cnt = 0\n",
    "    dict_edges = dict()\n",
    "    for edge in mst:\n",
    "        if edge[0] in dict_edges:\n",
    "            dict_edges[edge[0]][edge[1]] = edge[2]\n",
    "        else:\n",
    "            dict_edges[edge[0]] = {edge[1]: edge[2]}\n",
    "\n",
    "    while len(c[0]) < 1000:\n",
    "        number = mst[cnt][0]\n",
    "        cnt += 1\n",
    "        c = create_clusters([[number]], dict_edges)\n",
    "        print(len(c[0]))\n",
    "\n",
    "    new_mst = []\n",
    "    for edge in mst:\n",
    "        if edge[0] in c[0]:\n",
    "            new_mst.append(edge)\n",
    "\n",
    "    plotter.plot_without_coordinates(new_mst)\n",
    "    # plotter.set_vertex_coordinates(vertex_coordinates)\n",
    "    # plotter.set_dataset('rvisp24116')\n",
    "    # plotter.update_string()\n",
    "    # plotter.plot_mst_2d(mst)\n",
    "\n",
    "    print(len(mst), len(V))\n",
    "    print('Found MST in: ', datetime.now() - timestamp)\n",
    "    print('Done...')\n",
    "    for t in time:\n",
    "        print('Dataset generation took:', t)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initial call to main function\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
