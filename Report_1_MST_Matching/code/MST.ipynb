{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "qrrypVlYX-_5",
        "outputId": "cdd85b2e-7516-4bb5-8b72-3f9a9d4113f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd30980a700>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://59219597bdf7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# source: https://medium.com/grabngoinfo/install-pyspark-3-on-google-colab-the-easy-way-577ec4a2bcd8\n",
        "# Download Java Virtual Machine (JVM)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "# Unzip the file\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.3.1-bin-hadoop3'\n",
        "\n",
        "# Install library for finding Spark\n",
        "!pip install -q findspark\n",
        "# Import the libary\n",
        "import findspark\n",
        "# Initiate findspark\n",
        "findspark.init()\n",
        "# Check the location for Spark\n",
        "findspark.find()\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Check Spark Session Information\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWRMmX0caLyC",
        "outputId": "62446bda-181b-4b7a-dcf8-aff1ed936425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive\n",
        "# Need manual permission to access your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ZQ3GyIKFEl",
        "outputId": "e13b55d2-fcbb-4625-b524-0d510e907a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "o_kUvvr4aYc2"
      },
      "outputs": [],
      "source": [
        "# Algorithm by Kees Voorintholt\n",
        "# https://github.com/Keesiev7/MSTforDenseGraphs\n",
        "# Small modifications/bug fixes have been made\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "import scipy.spatial\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.datasets import make_circles, make_moons, make_blobs, make_swiss_roll, make_s_curve\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "\n",
        "def get_edge_weight(num_clusters=5, sigma=1, mu=None):\n",
        "    if mu is None:\n",
        "        mu = [5, 10, 15, 20, 25]\n",
        "    edge_cluster = np.ceil(random.uniform(0, num_clusters))\n",
        "    return np.random.normal(mu[edge_cluster], sigma)\n",
        "\n",
        "class DataReader:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def create_distance_matrix(self, dataset, full_dm=False):\n",
        "        \"\"\"\n",
        "        Creates the distance matrix for a dataset with only vertices. Also adds the edges to a dict.\n",
        "        :param dataset: dataset without edges\n",
        "        :return: distance matrix, a dict of all edges and the total number of edges\n",
        "        \"\"\"\n",
        "        vertices = []\n",
        "        size = 0\n",
        "        three_d = False\n",
        "        for line in dataset:\n",
        "            if len(line) == 2:\n",
        "                vertices.append([line[0], line[1]])\n",
        "            elif len(line) == 3:\n",
        "                vertices.append([line[0], line[1], line[2]])\n",
        "                three_d = True\n",
        "        if three_d:\n",
        "            max_weight = 0\n",
        "            dict = {}\n",
        "            for i in range(len(dataset)):\n",
        "                dict2 = {}\n",
        "                for j in range(i + 1, len(dataset)):\n",
        "                    value = np.sqrt(np.sum(np.square(dataset[i] - dataset[j])))\n",
        "                    max_weight = max(value, max_weight)\n",
        "                    dict2[j] = value\n",
        "                    size += 1\n",
        "                dict[i] = dict2\n",
        "        else:\n",
        "            d_matrix = scipy.spatial.distance_matrix(vertices, vertices, threshold=1000000)\n",
        "            dict = {}\n",
        "            max_weight = 0\n",
        "            # Run with less edges\n",
        "            for i in range(len(d_matrix)):\n",
        "                dict2 = {}\n",
        "                if full_dm:\n",
        "                    for j in range(len(d_matrix)):\n",
        "                        if i != j:\n",
        "                            size += 1\n",
        "                            max_weight = max(d_matrix[i][j], max_weight)\n",
        "                            dict2[j] = d_matrix[i][j]\n",
        "                    dict[i] = dict2\n",
        "                else:\n",
        "                    for j in range(i, len(d_matrix)):\n",
        "                        if i != j:\n",
        "                            size += 1\n",
        "                            max_weight = max(d_matrix[i][j], max_weight)\n",
        "                            dict2[j] = d_matrix[i][j]\n",
        "                    dict[i] = dict2\n",
        "        return dict, size, vertices, max_weight\n",
        "\n",
        "    def read_vertex_list(self, file_location):\n",
        "        vertices = []\n",
        "        with open(file_location) as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            for row in csv_reader:\n",
        "                vertices.append((float(row[0]), float(row[1])))\n",
        "        return vertices, len(vertices)\n",
        "\n",
        "    def read_csv_columns(self, file_location, column_names):\n",
        "        df = pd.read_csv(file_location, usecols=column_names)\n",
        "        V = []\n",
        "        for index, line in df.iterrows():\n",
        "            V.append((float(line[0]), float(line[1])))\n",
        "        return V, len(V)\n",
        "\n",
        "def get_key(item):\n",
        "    \"\"\"\n",
        "    returns the sorting criteria for the edges. All edges are sorted from small to large values\n",
        "    :param item: one item\n",
        "    :return: returns the weight of the edge\n",
        "    \"\"\"\n",
        "    return item[2]\n",
        "\n",
        "def create_clusters(clusters, dict_edges, flight_data = False):\n",
        "    i = 0\n",
        "    while i < len(clusters):\n",
        "        pop = False\n",
        "        for j in range(i):\n",
        "            if clusters[i][0] in clusters[j]:\n",
        "                clusters.pop(i)\n",
        "                pop = True\n",
        "                break\n",
        "        if pop:\n",
        "            continue\n",
        "\n",
        "        todo = []\n",
        "        if flight_data:\n",
        "          runningRange1 = 1000 # some big number\n",
        "        else:\n",
        "          runningRange1 = clusters[i][0]\n",
        "          \n",
        "\n",
        "        for j in range(clusters[i][0]):\n",
        "            if j in dict_edges:\n",
        "                if clusters[i][0] in dict_edges[j] and j not in clusters[i]:\n",
        "                    clusters[i].append(j)\n",
        "                    todo.append(j)\n",
        "\n",
        "        if clusters[i][0] in dict_edges:\n",
        "            for key in dict_edges[clusters[i][0]]:\n",
        "                todo.append(key)\n",
        "                clusters[i].append(key)\n",
        "\n",
        "        while len(todo) > 0:\n",
        "            first = todo.pop()\n",
        "            if flight_data:\n",
        "              runningRange2 = 1000 # some big number\n",
        "            else:\n",
        "              runningRange2 = first\n",
        "\n",
        "            for k in range(runningRange2):\n",
        "                if k in dict_edges:\n",
        "                    if first in dict_edges[k] and k not in clusters[i]:\n",
        "                        clusters[i].append(k)\n",
        "                        todo.append(k)\n",
        "\n",
        "            if first in dict_edges:\n",
        "                for key in dict_edges[first]:\n",
        "                    if key not in clusters[i]:\n",
        "                        clusters[i].append(key)\n",
        "                        todo.append(key)\n",
        "        i += 1\n",
        "\n",
        "    for i in range(len(clusters)):\n",
        "        clusters[i] = sorted(clusters[i])\n",
        "\n",
        "    return clusters\n",
        "\n",
        "\n",
        "class Plotter:\n",
        "    def __init__(self, vertex_coordinates, name_dataset, file_loc):\n",
        "        self.vertex_coordinates = vertex_coordinates\n",
        "        self.name_dataset = name_dataset\n",
        "        self.file_loc = file_loc\n",
        "        self.round = 0\n",
        "        self.colors = ['blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown',\n",
        "                       'blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown','blue', 'red', 'green', 'purple', 'yellow', 'darkorange', 'dodgerblue', 'deeppink', 'khaki', 'purple', 'springgreen', 'tomato', 'slategray', 'forestgreen', 'mistyrose', 'mediumorchid','rebeccapurple', 'lavender', 'cornflowerblue', 'lightseagreen', 'brown']\n",
        "        self.colors2 = ['#663399',\n",
        "                    '#ff0000',\n",
        "                    '#b22222',\n",
        "                    '#4682b4',\n",
        "                    '#663399',\n",
        "                    '#d2691e',\n",
        "                    '#8b008b',\n",
        "                    '#0000cd',\n",
        "                    '#00ff7f',\n",
        "                    '#a0522d',\n",
        "                    '#a52a2a',\n",
        "                    '#2e8b57',\n",
        "                    '#228b22',\n",
        "                    '#191970',\n",
        "                    '#006400',\n",
        "                    '#8b0000',\n",
        "                    '#808000',\n",
        "                    '#483d8b',\n",
        "                    '#b22222',\n",
        "                    '#5f9ea0',\n",
        "                    '#778899',\n",
        "                    '#3cb371',\n",
        "                    '#bc8f8f',\n",
        "                    '#663399',\n",
        "                    '#b8860b',\n",
        "                    '#bdb76b',\n",
        "                    '#008b8b',\n",
        "                    '#cd853f',\n",
        "                    '#00ff00',\n",
        "                    '#d2691e',\n",
        "                    '#9acd32',\n",
        "                    '#20b2aa',\n",
        "                    '#cd5c5c',\n",
        "                    '#00008b',\n",
        "                    '#4b0082',\n",
        "                    '#32cd32',\n",
        "                    '#daa520',\n",
        "                    '#8fbc8f',\n",
        "                    '#8b008b',\n",
        "                    '#b03060',\n",
        "                    '#66cdaa',\n",
        "                    '#9932cc',\n",
        "                    '#ff0000',\n",
        "                    '#ff4500',\n",
        "                    '#00ced1',\n",
        "                    '#ff8c00',\n",
        "                    '#ffa500',\n",
        "                    '#ffd700',\n",
        "                    '#6a5acd',\n",
        "                    '#ffff00',\n",
        "                    '#c71585',\n",
        "                    '#0000cd',\n",
        "                    '#7cfc00',\n",
        "                    '#deb887',\n",
        "                    '#40e0d0',\n",
        "                    '#00ff00',\n",
        "                    '#9400d3',\n",
        "                    '#ba55d3',\n",
        "                    '#00fa9a',\n",
        "                    '#8a2be2',\n",
        "                    '#00ff7f',\n",
        "                    '#4169e1',\n",
        "                    '#e9967a',\n",
        "                    '#dc143c',\n",
        "                    '#00ffff',\n",
        "                    '#00bfff',\n",
        "                    '#f4a460',\n",
        "                    '#9370db',\n",
        "                    '#0000ff',\n",
        "                    '#a020f0',\n",
        "                    '#f08080',\n",
        "                    '#adff2f',\n",
        "                    '#ff6347',\n",
        "                    '#da70d6',\n",
        "                    '#d8bfd8',\n",
        "                    '#b0c4de',\n",
        "                    '#ff7f50',\n",
        "                    '#ff00ff',\n",
        "                    '#1e90ff',\n",
        "                    '#db7093',\n",
        "                    '#f0e68c',\n",
        "                    '#fa8072',\n",
        "                    '#eee8aa',\n",
        "                    '#ffff54',\n",
        "                    '#6495ed',\n",
        "                    '#dda0dd',\n",
        "                    '#90ee90',\n",
        "                    '#add8e6',\n",
        "                    '#87ceeb',\n",
        "                    '#ff1493',\n",
        "                    '#7b68ee',\n",
        "                    '#ffa07a',\n",
        "                    '#afeeee',\n",
        "                    '#ee82ee',\n",
        "                    '#87cefa',\n",
        "                    '#7fffd4',\n",
        "                    '#ffe4b5',\n",
        "                    '#ffdab9',\n",
        "                    '#ff69b4',\n",
        "                    '#ffb6c1'\n",
        "                    ]\n",
        "        self.machine_string = \"{}_round_{}_machine_\".format(self.name_dataset, self.round)\n",
        "\n",
        "    def update_string(self):\n",
        "        self.machine_string = \"{}_round_{}_machine_\".format(self.name_dataset, self.round)\n",
        "\n",
        "    def set_dataset(self, name_dataset):\n",
        "        self.name_dataset = name_dataset\n",
        "\n",
        "    def set_vertex_coordinates(self, vertex_coordinates):\n",
        "        self.vertex_coordinates = vertex_coordinates\n",
        "\n",
        "    def set_file_loc(self, file_loc):\n",
        "        self.file_loc = file_loc\n",
        "\n",
        "    def reset_round(self):\n",
        "        self.round = 0\n",
        "\n",
        "    def next_round(self):\n",
        "        self.round += 1\n",
        "        self.update_string()\n",
        "\n",
        "    def plot_mst_2d(self, mst, intermediate=False, plot_cluster=False, plot_num_machines=0, num_clusters=2, basic_dataset = True):\n",
        "        x = []\n",
        "        y = []\n",
        "        c = []\n",
        "        area = []\n",
        "\n",
        "        for i in range(len(self.vertex_coordinates)):\n",
        "            x.append(float(self.vertex_coordinates[i][0]))\n",
        "            y.append(float(self.vertex_coordinates[i][1]))\n",
        "            area.append(0.1)\n",
        "            c.append('k')\n",
        "\n",
        "        if intermediate:\n",
        "            if not basic_dataset:\n",
        "              map_total = folium.Map(tiles='cartodbpositron', width=1920, height=1080)\n",
        "\n",
        "            if plot_num_machines > 0:\n",
        "                cnt = 0\n",
        "                for m in mst:\n",
        "                    plt.scatter(x, y, c=c, s=area)\n",
        "\n",
        "                    for i in range(len(m)):\n",
        "                        linex = [float(x[int(m[i][0])]), float(x[int(m[i][1])])]\n",
        "                        liney = [float(y[int(m[i][0])]), float(y[int(m[i][1])])]\n",
        "                        plt.plot(linex, liney, self.colors[cnt])\n",
        "                        if not basic_dataset:\n",
        "                          folium.PolyLine([ ( float(x[int(m[i][0])]), float(y[int(m[i][0])]) ) , ( float(x[int(m[i][1])]), float(y[int(m[i][1])]) )], color=self.colors2[cnt], weight=2, opacity=0.8).add_to(map_total)\n",
        "\n",
        "                    cnt = (cnt + 1) % len(self.colors)\n",
        "                    filename = self.file_loc + self.machine_string + '{}'.format(cnt)\n",
        "                    if not basic_dataset:\n",
        "                      map_total.save( filename + \".html\")\n",
        "                    plt.savefig(filename, dpi='figure')\n",
        "                    plt.clf()\n",
        "                    if cnt >= plot_num_machines:\n",
        "                        break\n",
        "\n",
        "            cnt = 0\n",
        "            for m in mst:\n",
        "                for i in range(len(m)):\n",
        "                    linex = [float(x[int(m[i][0])]), float(x[int(m[i][1])])]\n",
        "                    liney = [float(y[int(m[i][0])]), float(y[int(m[i][1])])]\n",
        "                    plt.plot(linex, liney, self.colors[cnt])\n",
        "                    if not basic_dataset:\n",
        "                      folium.PolyLine([ ( float(x[int(m[i][0])]), float(y[int(m[i][0])]) ) , ( float(x[int(m[i][1])]), float(y[int(m[i][1])]) )], color=self.colors2[cnt], weight=2, opacity=0.8).add_to(map_total)\n",
        "\n",
        "                cnt = (cnt + 1) % len(self.colors)\n",
        "            filename = self.file_loc + self.machine_string + 'all'\n",
        "\n",
        "            if not basic_dataset:\n",
        "              map_total.save( filename + \".html\")\n",
        "            plt.savefig(filename, dpi='figure')\n",
        "            plt.clf()\n",
        "        elif plot_cluster:\n",
        "            if not basic_dataset:\n",
        "              map_us = folium.Map(tiles='cartodbpositron', width=1920, height=1080)\n",
        "\n",
        "            edges = sorted(mst, key=get_key, reverse=True)\n",
        "\n",
        "            removed_edges = []\n",
        "            clusters = []\n",
        "            for i in range(num_clusters - 1):\n",
        "                edge = edges.pop(0)\n",
        "                removed_edges.append(edge)\n",
        "                clusters.append([edge[0]])\n",
        "                clusters.append([edge[1]])\n",
        "                linex = [float(x[edge[0]]), float(x[edge[1]])]\n",
        "                liney = [float(y[edge[0]]), float(y[edge[1]])]\n",
        "                plt.plot(linex, liney, \"k\")\n",
        "                if not basic_dataset:\n",
        "                  folium.PolyLine([ ( float(x[edge[0]]), float(y[edge[0]]) ) , ( float(x[edge[1]]), float(y[edge[1]]) )], color='black', weight=1, opacity=0.8).add_to(map_us)\n",
        "\n",
        "            dict_edges = dict()\n",
        "            for edge in edges:\n",
        "                if edge[0] in dict_edges:\n",
        "                    dict_edges[edge[0]].append(edge[1])\n",
        "                else:\n",
        "                    dict_edges[edge[0]] = [edge[1]]\n",
        "\n",
        "\n",
        "            clusters = create_clusters(clusters, dict_edges, flight_data=not basic_dataset)\n",
        "\n",
        "            x_cluster = []\n",
        "            y_cluster = []\n",
        "            c_cluster = []\n",
        "            area_cluster = []\n",
        "            \n",
        "            for i in range(len(clusters)):\n",
        "                for vertex in clusters[i]:\n",
        "                    if not basic_dataset: \n",
        "                      folium.CircleMarker(location=(float(self.vertex_coordinates[vertex][0]), float(self.vertex_coordinates[vertex][1])), radius=1,color=self.colors2[i], fill_color=self.colors2[i]).add_to(map_us) \n",
        "                      folium.CircleMarker(location=(float(self.vertex_coordinates[vertex][0]), float(self.vertex_coordinates[vertex][1])), radius=1,color=self.colors2[i], fill_color=self.colors2[i]).add_to(map_us) \n",
        "\n",
        "                    x_cluster.append(float(self.vertex_coordinates[vertex][0]))\n",
        "                    y_cluster.append(float(self.vertex_coordinates[vertex][1]))\n",
        "\n",
        "                    area_cluster.append(0.2)\n",
        "                    c_cluster.append(self.colors[i])\n",
        "\n",
        "            plt.scatter(x_cluster, y_cluster, c=c_cluster, s=area_cluster)\n",
        "\n",
        "            for i in range(len(mst)):\n",
        "                if mst[i] in removed_edges:\n",
        "                    continue\n",
        "                    \n",
        "                linex = [float(x[int(mst[i][0])]), float(x[int(mst[i][1])])]\n",
        "                liney = [float(y[int(mst[i][0])]), float(y[int(mst[i][1])])]\n",
        "\n",
        "                for j in range(len(clusters)):\n",
        "                    if mst[i][0] in clusters[j]:\n",
        "                        plt.plot(linex, liney, c=self.colors[j])\n",
        "                        if not basic_dataset:\n",
        "                          folium.PolyLine([ ( float(x[int(mst[i][0])]), float(y[int(mst[i][0])]) ) , ( float(x[int(mst[i][1])]), float(y[int(mst[i][1])]) )], color=self.colors2[j], weight=2, opacity=0.9).add_to(map_us)\n",
        "\n",
        "            filename = self.file_loc + self.name_dataset + '_clusters'\n",
        "            if not basic_dataset:\n",
        "              map_us.save( filename + \".html\")\n",
        "\n",
        "            plt.savefig(filename, dpi='figure')\n",
        "            plt.clf()\n",
        "\n",
        "        else:\n",
        "          # Plot the MST\n",
        "          if not basic_dataset:\n",
        "              map_us = folium.Map(tiles='cartodbpositron', width=1920, height=1080)\n",
        "\n",
        "          for i in range(len(mst)):\n",
        "              linex = [float(x[int(mst[i][0])]), float(x[int(mst[i][1])])]\n",
        "              liney = [float(y[int(mst[i][0])]), float(y[int(mst[i][1])])]\n",
        "              plt.plot(linex, liney)\n",
        "              if not basic_dataset:\n",
        "                folium.PolyLine([ ( float(x[int(mst[i][0])]), float(y[int(mst[i][0])]) ) , ( float(x[int(mst[i][1])]), float(y[int(mst[i][1])]) )], color=self.colors2[i % 100], weight=2, opacity=0.9).add_to(map_us)\n",
        "                \n",
        "          filename = self.file_loc + self.name_dataset + '_final'\n",
        "          if not basic_dataset:\n",
        "              map_us.save( filename + \".html\")\n",
        "          plt.savefig(filename, dpi='figure')\n",
        "          plt.clf()\n",
        "\n",
        "\n",
        "    def plot_cluster(self, yhat, final, vertex_coordinates):\n",
        "        clusters = set()\n",
        "        for v in yhat:\n",
        "            clusters.add(v)\n",
        "        color_ids = []\n",
        "        for item in clusters:\n",
        "            color_ids.append(item)\n",
        "        x = []\n",
        "        y = []\n",
        "        n = len(vertex_coordinates)\n",
        "        c = ['k'] * n\n",
        "        area = [0.1] * n\n",
        "        for x_c, y_c in vertex_coordinates:\n",
        "            x.append(float(x_c))\n",
        "            y.append(float(y_c))\n",
        "        plt.scatter(x, y, c=c, s=area)\n",
        "        for i in range(n):\n",
        "            cluster = yhat[i]\n",
        "            color = self.colors[0]\n",
        "            for j in range(len(color_ids)):\n",
        "                if cluster == color_ids[j]:\n",
        "                    color = self.colors[j % len(self.colors)]\n",
        "                    break\n",
        "            linex = [x[i], x[final[i]]]\n",
        "            liney = [y[i], y[final[i]]]\n",
        "            plt.plot(linex, liney, color)\n",
        "        # plt.show()\n",
        "        filename = self.file_loc + self.name_dataset + str(self.round)\n",
        "        plt.savefig(filename, dpi='figure')\n",
        "        plt.clf()\n",
        "\n",
        "def get_clustering_data():\n",
        "    \"\"\"\n",
        "    Retrieves all toy datasets from sklearn\n",
        "    :return: circles, moons, blobs datasets.\n",
        "    \"\"\"\n",
        "    n_samples = 1500\n",
        "    noisy_circles = make_circles(n_samples=n_samples, factor=.5,\n",
        "                                 noise=0.05)\n",
        "    noisy_moons = make_moons(n_samples=n_samples, noise=0.05)\n",
        "    blobs = make_blobs(n_samples=n_samples, random_state=8)\n",
        "    no_structure = np.random.rand(n_samples, 2), None\n",
        "\n",
        "    # Anisotropicly distributed data\n",
        "    random_state = 170\n",
        "    X, y = make_blobs(n_samples=4000, random_state=random_state)\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    X_aniso = np.dot(X, transformation)\n",
        "    aniso = (X_aniso, y)\n",
        "\n",
        "    # blobs with varied variances\n",
        "    varied = make_blobs(n_samples=4000,\n",
        "                        cluster_std=[1.0, 2.5, 0.5],\n",
        "                        random_state=random_state)\n",
        "\n",
        "    plt.figure(figsize=(9 * 2 + 3, 13))\n",
        "    plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.95, wspace=.05,\n",
        "                        hspace=.01)\n",
        "\n",
        "    swiss_roll = make_swiss_roll(n_samples, noise=0.05)\n",
        "\n",
        "    s_shape = make_s_curve(n_samples, noise=0.05)\n",
        "\n",
        "    temp = np.append(noisy_moons[0], [[2, 1.5]], axis=0)\n",
        "    noisy_moons = list(noisy_moons)\n",
        "    noisy_moons[0] = temp\n",
        "\n",
        "    datasets = [\n",
        "        # (noisy_circles, {'damping': .77, 'preference': -240,\n",
        "        #                  'quantile': .2, 'n_clusters': 2,\n",
        "        #                  'min_samples': 20, 'xi': 0.25}),\n",
        "        (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
        "        # (varied, {'eps': .18, 'n_neighbors': 2,\n",
        "        #           'min_samples': 5, 'xi': 0.035, 'min_cluster_size': .2}),\n",
        "        # (aniso, {'eps': .15, 'n_neighbors': 2,\n",
        "        #          'min_samples': 20, 'xi': 0.1, 'min_cluster_size': .2}),\n",
        "        # (blobs, {}),\n",
        "        # (no_structure, {}),\n",
        "        # (swiss_roll, {}),\n",
        "        # (s_shape, {})\n",
        "        ]\n",
        "\n",
        "    return datasets\n",
        "\n",
        "def create_distance_matrix(dataset):\n",
        "    \"\"\"\n",
        "    Creates the distance matrix for a dataset with only vertices. Also adds the edges to a dict.\n",
        "    :param dataset: dataset without edges\n",
        "    :return: distance matrix, a dict of all edges and the total number of edges\n",
        "    \"\"\"\n",
        "    vertices = []\n",
        "    size = 0\n",
        "    three_d = False\n",
        "    for line in dataset:\n",
        "        if len(line) == 2:\n",
        "            vertices.append([line[0], line[1]])\n",
        "        elif len(line) == 3:\n",
        "            vertices.append([line[0], line[1], line[2]])\n",
        "            three_d = True\n",
        "    if three_d:\n",
        "        dict = {}\n",
        "        for i in range(len(dataset)):\n",
        "            dict2 = {}\n",
        "            for j in range(i + 1, len(dataset)):\n",
        "                dict2[j] = np.sqrt(np.sum(np.square(dataset[i] - dataset[j])))\n",
        "                size += 1\n",
        "            dict[i] = dict2\n",
        "\n",
        "    else:\n",
        "        d_matrix = scipy.spatial.distance_matrix(vertices, vertices, threshold=1000000)\n",
        "        dict = {}\n",
        "        # Run with less edges\n",
        "        for i in range(len(d_matrix)):\n",
        "            dict2 = {}\n",
        "            for j in range(i, len(d_matrix)):\n",
        "                if i != j:\n",
        "                    size += 1\n",
        "                    dict2[j] = d_matrix[i][j]\n",
        "            dict[i] = dict2\n",
        "    return dict, size, vertices\n",
        "\n",
        "\n",
        "def partion_vertices(vertices, k):\n",
        "    \"\"\"\n",
        "    Partitioning of the vertices in k smaller subsets (creates a partitioning twice\n",
        "    :param vertices: all vertices\n",
        "    :param k: number of subsets that need to be created\n",
        "    :return: the partitioning in list format\n",
        "    \"\"\"\n",
        "    U = []\n",
        "    V = []\n",
        "    random.shuffle(vertices)\n",
        "    verticesU = vertices.copy()\n",
        "    random.shuffle(vertices)\n",
        "    verticesV = vertices.copy()\n",
        "    for i in range(len(vertices)):\n",
        "        if i < k:\n",
        "            U.append({verticesU[i]})\n",
        "            V.append({verticesV[i]})\n",
        "        else:\n",
        "            U[i % k].add(verticesU[i])\n",
        "            V[i % k].add(verticesV[i])\n",
        "    return U, V\n",
        "\n",
        "def get_key(item):\n",
        "    \"\"\"\n",
        "    returns the sorting criteria for the edges. All edges are sorted from small to large values\n",
        "    :param item: one item\n",
        "    :return: returns the weight of the edge\n",
        "    \"\"\"\n",
        "    return item[2]\n",
        "\n",
        "def find_mst(U, V, E):\n",
        "    \"\"\"\n",
        "    finds the mst of graph G = (U union V, E)\n",
        "    :param U: vertices U\n",
        "    :param V: vertices V\n",
        "    :param E: edges of the graph\n",
        "    :return: the mst and edges not in the mst of the graph\n",
        "     \"\"\"\n",
        "    vertices = set()\n",
        "    for v in V:\n",
        "        vertices.add(v)\n",
        "    for u in U:\n",
        "        vertices.add(u)\n",
        "    E = sorted(E, key=get_key)\n",
        "    connected_component = set()\n",
        "    mst = []\n",
        "    remove_edges = set()\n",
        "    while len(mst) < len(vertices) - 1 and len(connected_component) < len(vertices):\n",
        "        if len(E) == 0:\n",
        "            break\n",
        "        change = False\n",
        "        i = 0\n",
        "        while i < len(E):\n",
        "            if len(connected_component) == 0:\n",
        "                connected_component.add(E[i][0])\n",
        "                connected_component.add(E[i][1])\n",
        "                mst.append(E[i])\n",
        "                change = True\n",
        "                E.remove(E[i])\n",
        "                break\n",
        "            else:\n",
        "                if E[i][0] in connected_component:\n",
        "                    if E[i][1] in connected_component:\n",
        "                        remove_edges.add(E[i])\n",
        "                        E.remove(E[i])\n",
        "                    else:\n",
        "                        connected_component.add(E[i][1])\n",
        "                        mst.append(E[i])\n",
        "                        E.remove(E[i])\n",
        "                        change = True\n",
        "                        break\n",
        "                elif E[i][1] in connected_component:\n",
        "                    if E[i][0] in connected_component:\n",
        "                        remove_edges.add(E[i])\n",
        "                        E.remove(E[i])\n",
        "                    else:\n",
        "                        connected_component.add(E[i][0])\n",
        "                        mst.append(E[i])\n",
        "                        E.remove(E[i])\n",
        "                        change = True\n",
        "                        break\n",
        "                else:\n",
        "                    i += 1\n",
        "        if not change:\n",
        "            if len(E) != 0:\n",
        "                connected_component.add(E[0][0])\n",
        "                connected_component.add(E[0][1])\n",
        "                mst.append(E[0])\n",
        "                E.remove(E[0])\n",
        "    for edge in E:\n",
        "        remove_edges.add(edge)\n",
        "    if len(mst) != len(vertices) - 1 or len(connected_component) != len(vertices):\n",
        "        print('Warning: parition cannot have a full MST! Missing edges to create full MST.')\n",
        "        # print('Error: MST found cannot be correct \\n Length mst: ', len(mst), '\\n Total connected vertices: ',\n",
        "        #       len(connected_component), '\\n Number of vertices: ', len(vertices))\n",
        "    return mst, remove_edges\n",
        "\n",
        "def get_edges(U, V, E):\n",
        "    \"\"\"\n",
        "    :param U: subset of vertices (u_j)\n",
        "    :param V: subset of vertices (v_i)\n",
        "    :param E: all edges of the whole graph\n",
        "    :return: all edges that are part of the graph u_j U v_j\n",
        "    \"\"\"\n",
        "    edges = set()\n",
        "    for node1 in U:\n",
        "        for node2 in V:\n",
        "            if node1 in E:\n",
        "                if node2 in E[node1]:\n",
        "                    edges.add((node1, node2, E[node1][node2]))\n",
        "                elif node2 in E:\n",
        "                    if node1 in E[node2]:\n",
        "                        edges.add((node2, node1, E[node2][node1]))\n",
        "            elif node2 in E:\n",
        "                if node1 in E[node2]:\n",
        "                    edges.add((node2, node1, E[node2][node1]))\n",
        "    edge_list = []\n",
        "    for edge in edges:\n",
        "        edge_list.append(edge)\n",
        "    return U, V, edge_list\n",
        "\n",
        "\n",
        "def reduce_edges(vertices, E, c, epsilon):\n",
        "    \"\"\"\n",
        "    Uses PySpark to distribute the computation of the MSTs,\n",
        "    Randomly partition the vertices twice in k subsets (U = {u_1, u_2, .., u_k}, V = {v_1, v_2, .., v_k})\n",
        "    For every intersection between U_i and V_j, create the subgraph and find the MST in this graph\n",
        "    Remove all edges from E that are not part of the MST in the subgraph\n",
        "    :param vertices: vertices in the graph\n",
        "    :param E: edges of the graph\n",
        "    :param c: constant\n",
        "    :param epsilon:\n",
        "    :return:The reduced number of edges\n",
        "    \"\"\"\n",
        "    conf = SparkConf().setAppName('MST_Algorithm')\n",
        "    sc = SparkContext.getOrCreate(conf=conf)\n",
        "\n",
        "    n = len(vertices)\n",
        "    k = math.ceil(n ** ((c - epsilon) / 2))\n",
        "    print(\"k: \", k)\n",
        "    U, V = partion_vertices(vertices, k)\n",
        "\n",
        "    rddUV = sc.parallelize(U).cartesian(sc.parallelize(V)).map(lambda x: get_edges(x[0], x[1], E)).map(\n",
        "        lambda x: (find_mst(x[0], x[1], x[2])))\n",
        "    both = rddUV.collect()\n",
        "\n",
        "    mst = []\n",
        "    removed_edges = set()\n",
        "    for i in range(len(both)):\n",
        "        mst.append(both[i][0])\n",
        "        for edge in both[i][1]:\n",
        "            removed_edges.add(edge)\n",
        "\n",
        "    sc.stop()\n",
        "    return mst, removed_edges\n",
        "\n",
        "\n",
        "def remove_edges(E, removed_edges):\n",
        "    \"\"\"\n",
        "    Removes the edges, which are removed when generating msts\n",
        "    :param E: current edges\n",
        "    :param removed_edges: edges to be removed\n",
        "    :return: return the updated edge dict\n",
        "    \"\"\"\n",
        "    for edge in removed_edges:\n",
        "        if edge[1] in E[edge[0]]:\n",
        "            del E[edge[0]][edge[1]]\n",
        "    return E\n",
        "\n",
        "\n",
        "def create_mst(V, E, epsilon, size, vertex_coordinates, plot_intermediate=False, plotter=None):\n",
        "    \"\"\"\n",
        "    Creates the mst of the graph G = (V, E).\n",
        "    As long as the number of edges is greater than n ^(1 + epsilon), the number of edges is reduced\n",
        "    Then the edges that needs to be removed are removed from E and the size is updated.\n",
        "    :param plotter: class to plot graphs\n",
        "    :param V: Vertices\n",
        "    :param E: edges\n",
        "    :param epsilon:\n",
        "    :param size: number of edges\n",
        "    :param plot_intermediate: boolean to indicate if intermediate steps should be plotted\n",
        "    :param vertex_coordinates: coordinates of vertices\n",
        "    :return: returns the reduced graph with at most np.power(n, 1 + epsilon) edges\n",
        "    \"\"\"\n",
        "    n = len(V)\n",
        "    c = math.log(size / n, n)\n",
        "    print(\"C\", c)\n",
        "    total_runs = 0\n",
        "    while size > np.power(n, 1 + epsilon):\n",
        "        total_runs += 1\n",
        "        if plotter is not None:\n",
        "            plotter.next_round()\n",
        "        mst, removed_edges = reduce_edges(V, E, c, epsilon)\n",
        "        if plot_intermediate and plotter is not None:\n",
        "            if len(vertex_coordinates[0]) > 2:\n",
        "                plotter.plot_mst_3d(mst, intermediate=True, plot_cluster=False, plot_num_machines=1)\n",
        "            else:\n",
        "                plotter.plot_mst_2d(mst, intermediate=True, plot_cluster=False, plot_num_machines=1)\n",
        "        E = remove_edges(E, removed_edges)\n",
        "        print('Total edges removed in this iteration', len(removed_edges))\n",
        "        size = size - len(removed_edges)\n",
        "        print('New total of edges: ', size)\n",
        "        c = (c - epsilon) / 2\n",
        "\n",
        "    # Now the number of edges is reduced and can be moved to a single machine\n",
        "    V = set(range(n))\n",
        "    items = E.items()  # returns [(x, {y : 1})]\n",
        "    edges = []\n",
        "    for item in items:\n",
        "        items2 = item[1].items()\n",
        "        for item2 in items2:\n",
        "            edges.append((item[0], item2[0], item2[1]))\n",
        "    mst, removed_edges = find_mst(V, V, edges)\n",
        "    print(\"#####\\n\\nTotal runs: \", total_runs, \"\\n\\n#####\")\n",
        "    return mst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "llUvkrBV6kwE",
        "outputId": "54b11330-fe34-4ffb-c512-fc9aa190d195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting time: 2022-12-12 22:02:54.793887\n",
            "Start creating Distance Matrix...\n",
            "Size dataset:  1501\n",
            "Created distance matrix in:  0:00:00.622319\n",
            "Start creating MST...\n",
            "C 0.905137495141123\n",
            "k:  18\n",
            "Total edges removed in this iteration 1109255\n",
            "New total of edges:  16495\n",
            "k:  3\n",
            "Total edges removed in this iteration 13855\n",
            "New total of edges:  2640\n",
            "#####\n",
            "\n",
            "Total runs:  2 \n",
            "\n",
            "#####\n",
            "Found MST in:  0:01:36.731487\n",
            "Start creating plot of MST...\n",
            "Created plot of MST in:  0:00:04.085705\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1512x936 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    For every dataset, it creates the mst and plots the clustering\n",
        "    \"\"\"\n",
        "    start_time = datetime.now()\n",
        "    print('Starting time:', start_time)\n",
        "\n",
        "    datasets = get_clustering_data()\n",
        "    names_datasets = ['circles','moons']\n",
        "\n",
        "    num_clusters = [2,2,3, 3, 2, 2, 2]\n",
        "    cnt = 0\n",
        "    time = []\n",
        "    file_location = 'Results/Test/'\n",
        "    plotter = Plotter(None, None, file_location)\n",
        "    data_reader = DataReader()\n",
        "    for dataset in datasets:\n",
        "        if cnt < 0:\n",
        "            cnt += 1\n",
        "            continue\n",
        "        timestamp = datetime.now()\n",
        "        print('Start creating Distance Matrix...')\n",
        "        E, size, vertex_coordinates = create_distance_matrix(dataset[0][0])\n",
        "        plotter.set_vertex_coordinates(vertex_coordinates)\n",
        "        plotter.set_dataset(names_datasets[cnt])\n",
        "        plotter.update_string()\n",
        "        plotter.reset_round()\n",
        "        V = list(range(len(vertex_coordinates)))\n",
        "        print('Size dataset: ', len(vertex_coordinates))\n",
        "        print('Created distance matrix in: ', datetime.now() - timestamp)\n",
        "        print('Start creating MST...')\n",
        "        timestamp = datetime.now()\n",
        "        mst = create_mst(V, E, epsilon=1/8, size=size, vertex_coordinates=vertex_coordinates,\n",
        "                         plot_intermediate=True, plotter=plotter)\n",
        "        print('Found MST in: ', datetime.now() - timestamp)\n",
        "        time.append(datetime.now() - timestamp)\n",
        "        print('Start creating plot of MST...')\n",
        "        timestamp = datetime.now()\n",
        "        plotter.plot_mst_2d(mst, intermediate=False, plot_cluster=True, num_clusters=2)\n",
        "        plotter.plot_mst_2d(mst, intermediate=False, plot_cluster=False, num_clusters=2)\n",
        "        print('Created plot of MST in: ', datetime.now() - timestamp)\n",
        "        cnt += 1\n",
        "        \n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "O8B3gnjZaalk",
        "outputId": "911b7f26-d395-4abb-baea-b48e8972d82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size dataset:  358\n",
            "Created distance matrix in:  0:00:00.003825\n",
            "Start creating MST...\n",
            "C 0.4772935517712418\n",
            "k:  3\n",
            "Total edges removed in this iteration 4574\n",
            "New total of edges:  1353\n",
            "k:  2\n",
            "Total edges removed in this iteration 659\n",
            "New total of edges:  694\n",
            "#####\n",
            "\n",
            "Total runs:  2 \n",
            "\n",
            "#####\n",
            "Start creating plot of MST...\n",
            "Did everything in 0:00:08.423893\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Read the .csv file\n",
        "def read_data_set_from_csvfile(file_location):\n",
        "    edges = {}\n",
        "    vertices = []\n",
        "    size = 0\n",
        "    with open(file_location) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        line_count = 0\n",
        "        for row in csv_reader:\n",
        "          if line_count == 0:\n",
        "            line_count += 1\n",
        "            continue\n",
        "          \n",
        "          line_count += 1\n",
        "\n",
        "          v1_id = int(row[1])\n",
        "          v2_id = int(row[4])\n",
        "\n",
        "          if not [float(row[2]), float(row[3])] in vertices:\n",
        "            vertices.append([float(row[2]), float(row[3])])\n",
        "\n",
        "          if not [float(row[5]), float(row[6])] in vertices:\n",
        "            vertices.append([float(row[5]), float(row[6])])\n",
        "\n",
        "          if v1_id in edges:\n",
        "              edges[v1_id][v2_id] = float(row[7])\n",
        "              size += 1\n",
        "          else:\n",
        "              edges[v1_id] = {v2_id: float(row[7])}\n",
        "              size += 1\n",
        "\n",
        "    return vertices, size, edges\n",
        "\n",
        "vertices, size, edges = read_data_set_from_csvfile('Results/flight_data.csv')\n",
        "\n",
        "file_location = 'Results/Flights/'\n",
        "plotter = Plotter(None, None, file_location)\n",
        "timestamp = datetime.now()\n",
        "E, size, vertex_coordinates = edges, size, vertices\n",
        "plotter.set_vertex_coordinates(vertex_coordinates)\n",
        "plotter.set_dataset('flight_data_2')\n",
        "plotter.update_string()\n",
        "plotter.reset_round()\n",
        "V = list(range(len(vertex_coordinates)))\n",
        "print('Size dataset: ', len(vertex_coordinates))\n",
        "print('Created distance matrix in: ', datetime.now() - timestamp)\n",
        "print('Start creating MST...')\n",
        "timestamp = datetime.now()\n",
        "mst = create_mst(V, E, epsilon=1/8, size=size, vertex_coordinates=vertex_coordinates, plot_intermediate=True, plotter=plotter)\n",
        "print('Start creating plot of MST...')\n",
        "\n",
        "plotter.plot_mst_2d(mst, intermediate=False, plot_cluster=True, num_clusters=7, basic_dataset=False)\n",
        "print('Did everything in', datetime.now() - timestamp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}